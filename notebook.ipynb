{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Project Description__\n",
    "\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "\n",
    "The goal of the project is to determine will the client subscribe a bank term deposit\n",
    "\n",
    "## __Referenced papers__\n",
    "1. https://ieeexplore.ieee.org/abstract/document/9065648\n",
    "2. https://www.researchgate.net/publication/323198261_Customer_Profiling_using_Classification_Approach_for_Bank_Telemarketing\n",
    "3. https://ieeexplore.ieee.org/abstract/document/8391441\n",
    "4. https://ieeexplore.ieee.org/document/9655824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Exploratory Data Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read the dataset into dataframe. Notice that the dataset is a csv file but separated by `;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./dataset/bank-additional/bank-additional.csv\",sep=\";\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop column __duration__, according to UCI:    \n",
    "\n",
    "> ` this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"duration\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting info of dataframe. There is no null data in any of the feature. So we don't need to handle this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, show_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Visualization__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing distribution of categorical features and label using pie chart. As can be seen, we have a fairly imbalanced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pie_visualization = [\"job\", \"marital\", \"education\",\n",
    "                     \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"day_of_week\", \"poutcome\",  \"y\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(18, 10))\n",
    "\n",
    "for i, feature in enumerate(pie_visualization):\n",
    "    category = df[feature].value_counts()\n",
    "    axes.flat[i].set_title(\"Distribution of {}\".format(feature))\n",
    "    axes.flat[i].pie(category, labels=category.index, autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing when the data is normally collected. As can be seen, most of the data is collected around May. The day_of_week is fairly balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_visualization = [\"day_of_week\", \"month\"]\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n",
    "for i, ax in enumerate(axes.flat, start=0):\n",
    "    feature = bar_visualization[i]\n",
    "    df[feature].value_counts().plot(kind=\"barh\", ax=ax,title=\"Frequency of {}\".format(feature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing correlation between numeric features    \n",
    "\n",
    "As can be noticed from the graph, `emp.var.rate`, `nr.employed`, `euribor3m`,`cons.price.index` are highly correlated\n",
    "Depending on the algorithm, we may need remove one of the above listed features. This is a **Multicollinearity** problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 8, 5\n",
    "numerical_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\",\n",
    "                      \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"]\n",
    "\n",
    "corr = df[numerical_features].corr()\n",
    "print(type(corr))\n",
    "sb.heatmap(corr, cmap=\"Blues\", annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical features, we are also interested in their distributions. \n",
    "\n",
    "As can be seen, there are lots of outliers in age, campaign, pdays, previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ceil(len(numerical_features)/2),2, figsize=(10, 10))\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    df.boxplot(column=feature, ax=axes.flat[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For features with many outliers, count frequency\n",
    "\n",
    "We notice that, people between 25 and 60 years old will likely to invest.\n",
    "\n",
    "For `campaign`, there are many who gets contacted by bank representative by the first time, the same can be said for `pdays` and `previous`.\n",
    "\n",
    "Potentially, we need to remove outliers from the 4 mentioned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_outliers = [\"campaign\", \"pdays\", \"previous\"]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 10))\n",
    "\n",
    "df[\"age\"].value_counts(bins=10).plot(kind=\"barh\", title=\"Frequency of age\")\n",
    "\n",
    "for i, feature in enumerate(feature_outliers):\n",
    "    df[feature].value_counts().plot(\n",
    "        kind=\"barh\", ax=axes.flat[i], title=\"Frequency of {}\".format(feature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepare data for ML algorithms__\n",
    "\n",
    "Some ML algorithms do not work well with categorical data, therefore, we need to convert those categorical data to number.\n",
    "\n",
    "There are several features that are strictly __nominal__, perform **One Hot Encoder** on these features. Some features are __ordinal__, with these features, we perform **Ordinal Encoder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Ordering array from low to high\n",
    "# The first element has lowest priority, the last element has highest priority\n",
    "# This ranking is important!!\n",
    "education = [\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\",\n",
    "             \"unknown\", \"high.school\", \"professional.course\", \"university.degree\"]\n",
    "\n",
    "credit_default = [\"yes\", \"unknown\", \"no\"]\n",
    "\n",
    "poutcome = [\"failure\", \"nonexistent\", \"success\"]\n",
    "\n",
    "# 0 means no, 1 means yes\n",
    "y = [\"no\", \"yes\"]\n",
    "\n",
    "columnTransformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", OneHotEncoder(), [\n",
    "         \"job\", \"marital\", \"contact\", \"housing\", \"loan\", \"day_of_week\", \"month\"]),\n",
    "        (\"OrdinalEncoder\", OrdinalEncoder(\n",
    "            categories=[education, credit_default, poutcome, y]),\n",
    "            [\"education\", \"default\", \"poutcome\", \"y\"]),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "transformed_df = pd.DataFrame(\n",
    "    columnTransformer.fit_transform(df),\n",
    "    columns=columnTransformer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Need to find out a way to feature engineering day and month\n",
    "# Cannot use label encoding these data are cyclical data in nature\n",
    "# Refer https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html\n",
    "# Also, should housing and loan be in encoded using OrdinalEncoder or OneHotEncoder?\n",
    "# I feel like there is no direct ranking between them so to play it safe, I use OneHotEncoder for it\n",
    "\n",
    "transformed_df.info(verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the encoder, we notice that the `dtypes` of dataframe is `float64` for all features!\n",
    "Now we separate features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transformed_df.drop(columns=[\"OrdinalEncoder__y\"])\n",
    "y = transformed_df[\"OrdinalEncoder__y\"]\n",
    "\n",
    "print(x.info(verbose=False))\n",
    "print(y.info(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper 2\n",
    "\n",
    "Link: https://www.researchgate.net/publication/323198261_Customer_Profiling_using_Classification_Approach_for_Bank_Telemarketing\n",
    "\n",
    "Using C4.5 algorithm to predict if a client will subscribe a term deposit.  \n",
    "\n",
    "In theory, decision tree should be able to work with categorical data. However, the current implementation of   \n",
    "decision tree in scikit-learn 1.1 does not handle categorical data. Refer https://scikit-learn.org/1.1/modules/tree.html    \n",
    "\n",
    "As a result, we need to use OneHotEncoder and Ordinal Encoder on the features. `transformed_df` variable is a dataframe that\n",
    "has all features encoded.\n",
    "\n",
    "There are trades off of doing this, notably higher tree depth and the time it takes for the algorithm to finish is longer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def report_result(y_pred, y_true, clf):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=clf.classes_)\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm, display_labels=clf.classes_)\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "def tree_visualizer(tree_classifier, feature_names):\n",
    "    fig = plt.figure(figsize=(25, 20))\n",
    "    _ = tree.plot_tree(tree_classifier,\n",
    "                       feature_names=feature_names,\n",
    "                       class_names=['No', \"Yes\"],\n",
    "                       filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# The following features are not used by the paper, therefore, we're not going to use these features as well\n",
    "tree_dataset_x = x.drop(columns=[\"remainder__euribor3m\", \"remainder__nr.employed\",\n",
    "                                 \"remainder__cons.price.idx\", \"remainder__emp.var.rate\", \"remainder__cons.conf.idx\"], inplace=False)\n",
    "\n",
    "# Seperate into train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    tree_dataset_x, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create validation set\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "    x_train, y_train, train_size=0.6, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "tree_clf.fit(X_train, Y_train)\n",
    "y_pred = tree_clf.predict(x_test)\n",
    "report_result(y_pred, y_test, tree_clf)\n",
    "tree_visualizer(tree_clf, X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameter tuning with decision tree\n",
    "\n",
    "We do not need to scale data in order to use decision tree, thus it will be skipped.\n",
    "\n",
    "The scoring criteria here will be `balanced_accuracy`, this is to account for our imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dec_tree = DecisionTreeClassifier(random_state=0)\n",
    "pipe = Pipeline(steps=[\n",
    "    ('dec_tree', dec_tree)])\n",
    "\n",
    "parameters = dict(\n",
    "    dec_tree__class_weight=[\"balanced\"],\n",
    "    dec_tree__criterion=['gini', 'entropy'],\n",
    "    dec_tree__max_depth=[2, 4, 6, 8, 10],\n",
    "    dec_tree__splitter=[\"best\", \"random\"],\n",
    "    dec_tree__max_features=[\"sqrt\", \"log2\", None]\n",
    ")\n",
    "\n",
    "tree_tuning = GridSearchCV(pipe, parameters, scoring=[\n",
    "                           \"accuracy\", \"recall\", \"balanced_accuracy\"], refit=\"accuracy\")\n",
    "tree_tuning.fit(X_valid, Y_valid)\n",
    "print(\"Best params\", tree_tuning.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tuned parameters on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_result(tree_tuning.predict(x_test), y_test, tree_tuning)\n",
    "tree_visualizer(tree_tuning.best_estimator_.get_params()['dec_tree'], x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper result mentioned that on testing data, they achivieved `90.09%`, `59.06%`, `93.23%` on accuracy score, specificity, and sensitivity respectively. \n",
    "\n",
    "As for our result, we achieved `91%` on accuracy score, `67%` on specitivity score and finally `91%` on sensitivity score.\n",
    "\n",
    "Compared to the paper result, we found out that we are better at overall accuracy of the algorithm as well as correctly identifying term deposit subscriber.\n",
    "\n",
    "However, there are a lot of room for improvement with the algorithm, for example, the recall rate of term deposit subscriber is only at `8%` only. Meaning, we are missing out on a lot of other potential customers."
   ]
  },
  {
   "source": [
    "## Paper 3\n",
    "\n",
    "Reserch Paper 3 : https://ieeexplore.ieee.org/abstract/document/9065648\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.902913\nPrecision: 0.877134\nRecall: 0.902913\nF1: 0.881020\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(x)\n",
    "feature_pca = pca.transform(x)\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(feature_pca, y, random_state=0)\n",
    "\n",
    "neigh_PCA = KNeighborsClassifier(n_neighbors=4, algorithm = \"brute\", weights=\"uniform\")\n",
    "neigh_PCA.fit(X_trainP, y_trainP)\n",
    "\n",
    "accuracy_PCA = neigh_PCA.score(X_testP, y_testP)\n",
    "print(\"Accuracy: %f\" % accuracy_PCA)\n",
    "\n",
    "y_test_pred = neigh_PCA.predict(X_testP)\n",
    "print(\"Precision: %f\" % precision_score(y_testP, y_test_pred, average='weighted'))\n",
    "print(\"Recall: %f\" % recall_score(y_testP, y_test_pred, average='weighted'))\n",
    "print(\"F1: %f\" % f1_score(y_testP, y_test_pred, average='weighted'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Results\n",
    "The Accuracy result in the Research Paper of KNN is 89.80 with CfsSubsetEval dimension reduction. While our Accuracy scrore for KNN with PCA dimension reduction is 90.29. \n",
    "Clearly our result is better than that of the Research Paper.It can be duduced that our implementation performed better because we used PCA instead of CfsSubsetEval for dimension reduction. The main area of focus in this research paper is accuracy but when comparing other mertics we get the following Results: <br> Our Precision scrore is 0.877 while research paper's is 0.887. <br>Our Recall scrore is 0.9029 while research paper's is 0.898.<br> Our F1 scrore is 0.881 while research paper's is 0.891\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13-final"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "798686119d06974c77af5d54bc229013fc34e695772a3d913a0b53154d99f685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}